{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: The main task is Speech Translation: translating audio in one language to text in another language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial experiments on one pair of languages: English --> German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the working directory to the root of the project\n",
    "os.chdir(r'C:\\Users\\TuAhnDinh\\Desktop\\MediaanProjects\\BachelorThesisST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covost_data_preparation import read_tsv_split\n",
    "\n",
    "COVOST_DIR = 'data/CoVoST2'\n",
    "PREPROCESSED_DIR = 'preprocessed/full'\n",
    "\n",
    "src_lang = 'en'\n",
    "en_X_dir = f'{COVOST_DIR}/{PREPROCESSED_DIR}/en-X'\n",
    "SRC_AUDIO_DIR = COVOST_DIR + '/' + src_lang\n",
    "audiodir = SRC_AUDIO_DIR + '/clips'\n",
    "tgt_lang = 'de'\n",
    "TRANSLATIONS_DIR = COVOST_DIR + '/covost2' + f'/{src_lang}_{tgt_lang}'\n",
    "\n",
    "test_df = read_tsv_split(TRANSLATIONS_DIR, src_lang=src_lang, tgt_lang=tgt_lang, split='test', audiodir=audiodir)\n",
    "test_audios_list = [audiodir + '/' + path for path in test_df['path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: CoVoST2\n",
    "\n",
    "English audio - English transcription - German translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('data/CoVoST2/en_X_stat.csv', index_col=0, header=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics explaination\n",
    "\n",
    "- For Speech Recognition tasks: use Word error rate (WER) <br>\n",
    "    WER = (number of wrongly-transcribed words) / (number of all words) <br>\n",
    "    WER ranges from 0-100, the smaller the better\n",
    "    \n",
    "    \n",
    "- For translation tasks: BLEU score <br>\n",
    "    30 - 40\tUnderstandable to good translations<br>\n",
    "    40 - 50\tHigh quality translations<br>\n",
    "    50 - 60\tVery high quality, adequate, and fluent translations<br>\n",
    "    \\> 60\tQuality often better than human<br>\n",
    "    BLEU score ranges from 0-100, the bigger the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascaded approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic Speech Recognition (ASR) model: English audio --> English text \n",
    "\n",
    "WER score on the test set: 29.7 <br>\n",
    "(the baseline in CoVoST paper gives 25.6)\n",
    "\n",
    "Result on a test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "with open(\"experiments/audio_en_text_en/raw_text_translation.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    output_texts = f.readlines()\n",
    "    \n",
    "sample_index = 100\n",
    "sample_audio = test_audios_list[sample_index]\n",
    "print('English audio')\n",
    "display(Audio(filename=sample_audio, autoplay=False))\n",
    "print('English text output by the model:')\n",
    "print(output_texts[sample_index])\n",
    "print('Human-labled English transcription:')\n",
    "print(test_df.loc[sample_index]['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Translation (MT) model: English text --> German text\n",
    "\n",
    "BLEU score on the test set: 33.0 <br>\n",
    "(the baseline in CoVoST paper gives 29.0)\n",
    "\n",
    "Result on a test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "with open(\"experiments/text_en_text_de/raw_text_translation.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    output_texts = f.readlines()\n",
    "    \n",
    "sample_index = 100\n",
    "sample_audio = test_audios_list[sample_index]\n",
    "output_text = output_texts[sample_index]\n",
    "reference_text = test_df.loc[sample_index]['translation']\n",
    "\n",
    "print('English text')\n",
    "print(test_df.loc[sample_index]['sentence'])\n",
    "print()\n",
    "print('German text output by the model:')\n",
    "print(output_text)\n",
    "print('Human-labled German translation:')\n",
    "print(reference_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cascaded Speech Translation (ST) using the above 2 models: English audio --> English text --> German text\n",
    "\n",
    "BLEU score on the test set: 20.6 <br>\n",
    "(the baseline in CoVoST paper gives 18.3)\n",
    "\n",
    "Result on a test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments/cascaded_ST_en_de/raw_text_output.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    output_texts = f.readlines()\n",
    "    \n",
    "sample_index = 100\n",
    "sample_audio = test_audios_list[sample_index]\n",
    "output_text = output_texts[sample_index]\n",
    "reference_text = test_df.loc[sample_index]['translation']\n",
    "\n",
    "print('English audio')\n",
    "display(Audio(filename=sample_audio, autoplay=False))\n",
    "print('German text output by the model:')\n",
    "print(output_text)\n",
    "print('Human-labled German translation:')\n",
    "print(reference_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end approach\n",
    "\n",
    "#### Speech Translation (ST) model: English audio --> German text\n",
    "\n",
    "BLEU score on the test set: 14.9 <br>\n",
    "(the baseline in CoVoST paper gives 13.6)\n",
    "\n",
    "Result on a test sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments/audio_en_text_de/raw_text_output.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    output_texts = f.readlines()\n",
    "    \n",
    "sample_index = 100\n",
    "sample_audio = test_audios_list[sample_index]\n",
    "output_text = output_texts[sample_index]\n",
    "reference_text = test_df.loc[sample_index]['translation']\n",
    "\n",
    "print('English audio')\n",
    "display(Audio(filename=sample_audio, autoplay=False))\n",
    "print('German text output by the model:')\n",
    "print(output_text)\n",
    "print('Human-labled German translation:')\n",
    "print(reference_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step:\n",
    "\n",
    "Combine MT and ASR into one model: <br>\n",
    "English audio --> English text <br>\n",
    "English text --> German text <br>\n",
    "\n",
    "And run Zero-shot:\n",
    "English audio --> German text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
