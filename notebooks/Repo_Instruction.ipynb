{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEyHS2n_2cUo"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbTp3bE4oHx2"
   },
   "source": [
    "Cloning if used on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_waF_8W15Vi"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/TuAnh23/MultiModalST.git\n",
    "cd tuanh_thesis\n",
    "git pull origin master\n",
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhazQiFUoa_N"
   },
   "source": [
    "Change working directory to the root of the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwKpTxyO2eqE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('tuanh_thesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlGVyHnd2s-f"
   },
   "source": [
    "# Repository usage instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ4P_8TI660S"
   },
   "source": [
    "## 1. Environment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAMqPYwI7JaQ"
   },
   "source": [
    "Use a Conda environment with `python=3.7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwfT92sq7h-K"
   },
   "outputs": [],
   "source": [
    "# try to run the bare minimum to get a new conda env working\n",
    "conda_path = ''\n",
    "try:\n",
    "    conda_path = !which conda\n",
    "finally:\n",
    "    print('')\n",
    "\n",
    "if (len(conda_path) == 0):\n",
    "    print('installing miniconda')\n",
    "    !wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.9.2-Linux-x86_64.sh && bash Miniconda3-py37_4.9.2-Linux-x86_64.sh -bfp /usr/local\n",
    "    !source /usr/local/etc/profile.d/conda.sh\n",
    "    !conda init \n",
    "    !conda install -n root _license -y -q\n",
    "else:\n",
    "    print('found miniconda')\n",
    "\n",
    "conda_envs = !conda env list\n",
    "res = [i for i in conda_envs if 'BachelorThesisST' in i]\n",
    "if (len(res) == 0):\n",
    "    print('not found BachelorThesisST env', len(res))\n",
    "    !conda create -y -q --name BachelorThesisST python=3.7 conda=4.9.2 \n",
    "else:\n",
    "    print('found BachelorThesisST env', len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gkulo-LP7uEu"
   },
   "source": [
    "Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMAzOwmE70p3"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate BachelorThesisST\n",
    "conda install -y numpy\n",
    "conda install -y pandas\n",
    "conda install -y -c conda-forge sentencepiece\n",
    "conda install -y pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch\n",
    "conda install -y -c anaconda hdf5\n",
    "conda install -y -c conda-forge nvidia-apex\n",
    "conda install -y -c conda-forge librosa\n",
    "conda install -y -c powerai sacrebleu\n",
    "conda install -y h5py\n",
    "pip install kaldiio\n",
    "pip install vizseq\n",
    "git clone https://github.com/thomasZen/python_speech_features2\n",
    "cd python_speech_features2 \n",
    "python setup.py install\n",
    "cd ../\n",
    "conda install -y ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0G8TDbk23Go"
   },
   "source": [
    "## 2. Download and prepare [Covost 2](https://github.com/facebookresearch/covost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHm_mAIT96cq"
   },
   "source": [
    "Create data folders.\n",
    "\n",
    "`full`, `one_half`, `one_fourth`,... denote the portion of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kno0haad9_ax"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir data\n",
    "mkdir data/CoVoST2\n",
    "mkdir data/CoVoST2/preprocessed\n",
    "mkdir data/CoVoST2/preprocessed/one_seventy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-i4y5aG9_j7"
   },
   "source": [
    "Let's download and prepare a small data pair as an example: NL speech --> EN text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrPvBiji3aBH"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate BachelorThesisST\n",
    "python \n",
    "# ----------- Activate the conda env in every cell, neccessary if using Google colab. Remove the above lines if not needed -----------\n",
    "\n",
    "from covost_data_preparation import download, prepare_X_to_en_data\n",
    "\n",
    "SRC_LANG = 'nl'\n",
    "TGT_lang = 'en'\n",
    "\n",
    "print('Downloading Covost data')\n",
    "\n",
    "# CommonVoice urls for the audio\n",
    "urls = {SRC_LANG: f'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/{SRC_LANG}.tar.gz'}\n",
    "# Specify language pair\n",
    "XX_EN_LANGUAGES = [SRC_LANG]\n",
    "\n",
    "download(urls, en_xx_languages=[], xx_en_languages=XX_EN_LANGUAGES)\n",
    "\n",
    "print('Preparing Covost data')\n",
    "prepare_X_to_en_data([SRC_LANG], training_portion=0.0143) # Use 1.43% of the training data only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuDS_tjJZGq0"
   },
   "source": [
    "At this point:\n",
    "- .mp3 audio is saved in `nl`\n",
    "- raw transcription and translation is saved in `covost2`\n",
    "- prepared data is saved in `preprocessed`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlJp3sklNF8q"
   },
   "source": [
    "## 3. Preprocess data and train models\n",
    "\n",
    "- Preprocess data: `preprocess.py`\n",
    "- Train models: `train.py`\n",
    "- Evaluate: `translate.py` and `translation_evaluation.py`\n",
    "\n",
    "We will train and evaluate a plain ZS model as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWJZ_OXdYE1t"
   },
   "source": [
    "Preprocess ASR and MT data.\n",
    "\n",
    "The preprocessed data is stored at `data/CoVoST2/preprocessed/one_seventy/nl-en/mix_nl_text_de`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzhdtBVyNdnT"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate BachelorThesisST\n",
    "# ----------- Activate the conda env in every cell, neccessary if using Google colab. Remove the above lines if not needed -----------\n",
    "DATA_DIR=data/CoVoST2/preprocessed/one_seventy/nl-en\n",
    "SUB_DIR=mix_nl_text_de\n",
    "echo \"Preprocessing ${SUB_DIR} data\"\n",
    "mkdir ${DATA_DIR}/${SUB_DIR} \n",
    "# Create a vocabulary for all text sources and targets\n",
    "python vocab_generator.py -filenames \"$DATA_DIR/nl_text_train.txt|${DATA_DIR}/en_text_train.txt\" \\\n",
    "    -out_file $DATA_DIR/${SUB_DIR}/src_tgt_vocab\n",
    "# Use the above vocabs while preprocessing\n",
    "# Preprocess ASR data\n",
    "python preprocess.py -train_src $DATA_DIR/nl_audio_train.scp  \\\n",
    "    -train_tgt $DATA_DIR/nl_text_train.txt  \\\n",
    "    -valid_src $DATA_DIR/nl_audio_val.scp  \\\n",
    "    -valid_tgt $DATA_DIR/nl_text_val.txt  \\\n",
    "    -train_src_lang nl \\\n",
    "    -train_tgt_lang nl \\\n",
    "    -valid_src_lang nl \\\n",
    "    -valid_tgt_lang nl \\\n",
    "    -all_langs \"nl|en\" \\\n",
    "    -src_seq_length 1024  \\\n",
    "    -tgt_seq_length 512  \\\n",
    "    -concat 4 \\\n",
    "    -asr \\\n",
    "    -src_type audio \\\n",
    "    -asr_format scp \\\n",
    "    -save_data $DATA_DIR/${SUB_DIR}/asr_data \\\n",
    "    -format scp \\\n",
    "    -tgt_vocab $DATA_DIR/${SUB_DIR}/src_tgt_vocab\n",
    "# Preprocess MT data\n",
    "python preprocess.py -train_src $DATA_DIR/nl_text_train.txt  \\\n",
    "    -train_tgt $DATA_DIR/en_text_train.txt  \\\n",
    "    -valid_src $DATA_DIR/nl_text_val.txt  \\\n",
    "    -valid_tgt $DATA_DIR/en_text_val.txt  \\\n",
    "    -train_src_lang nl \\\n",
    "    -train_tgt_lang en \\\n",
    "    -valid_src_lang nl \\\n",
    "    -valid_tgt_lang en \\\n",
    "    -all_langs \"nl|en\" \\\n",
    "    -src_seq_length 512  \\\n",
    "    -tgt_seq_length 512  \\\n",
    "    -concat 1 \\\n",
    "    -src_type text \\\n",
    "    -save_data $DATA_DIR/${SUB_DIR}/mt_data \\\n",
    "    -format mmem \\\n",
    "    -src_vocab $DATA_DIR/${SUB_DIR}/src_tgt_vocab \\\n",
    "    -tgt_vocab $DATA_DIR/${SUB_DIR}/src_tgt_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoDV0RtMbZ2s"
   },
   "source": [
    "Train a dummy model.\n",
    "\n",
    "Model checkpoints and experiment results are stored at `models/mix_nl_text_en_dummy`, `experiments/mix_nl_text_en_dummy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSmIca4kblhd"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate BachelorThesisST\n",
    "# ----------- Activate the conda env in every cell, neccessary if using Google colab. Remove the above lines if not needed -----------\n",
    "DATA_DIR=data/CoVoST2/preprocessed/one_seventy/nl-en\n",
    "SUB_DIR=mix_nl_text_de\n",
    "MODEL_DIR=models/${SUB_DIR}_dummy\n",
    "EXPERIMENT_DIR=experiments/${SUB_DIR}_dummy\n",
    "mkdir ${MODEL_DIR}\n",
    "mkdir ${EXPERIMENT_DIR}\n",
    "python -u train.py -data ${DATA_DIR}/${SUB_DIR}/asr_data \\\n",
    "  $cont_checkpoint_str \\\n",
    "  -data_format scp \\\n",
    "  -additional_data \"${DATA_DIR}/${SUB_DIR}/mt_data\" \\\n",
    "  -additional_data_format mmem \\\n",
    "  -data_ratio -1 \\\n",
    "  -use_language_embedding \\\n",
    "  -language_embedding_type concat \\\n",
    "  -save_model ${MODEL_DIR}/model \\\n",
    "  -model transformer \\\n",
    "  -batch_size_words 2048 \\\n",
    "  -batch_size_update 24568 \\\n",
    "  -batch_size_sents 9999 \\\n",
    "  -batch_size_multiplier 8 \\\n",
    "  -encoder_type mix \\\n",
    "  -checkpointing 0 \\\n",
    "  -input_size $((80*4)) \\\n",
    "  -concat 4 \\\n",
    "  -layers 12 \\\n",
    "  -audio_encoder_layers 32 \\\n",
    "  -text_encoder_layers 12 \\\n",
    "  -share_encoders_parameter all_text_enc \\\n",
    "  -death_rate 0.0 \\\n",
    "  -model_size 512 \\\n",
    "  -inner_size $((512*4)) \\\n",
    "  -n_heads 8 \\\n",
    "  -dropout 0.2 \\\n",
    "  -attn_dropout 0.2 \\\n",
    "  -word_dropout 0.1 \\\n",
    "  -emb_dropout 0.2 \\\n",
    "  -label_smoothing 0.1 \\\n",
    "  -epochs 5 \\\n",
    "  -optim adam \\\n",
    "  -learning_rate 0.001 \\\n",
    "  -normalize_gradient \\\n",
    "  -warmup_steps 8000 \\\n",
    "  -tie_weights \\\n",
    "  -join_embedding \\\n",
    "  -seed 8877 \\\n",
    "  -log_interval 1000 \\\n",
    "  -update_frequency -1 \\\n",
    "  -gpus 0 | tee -a ${EXPERIMENT_DIR}/train.log\n",
    "  sed '/.*Validation perplexity.*/{s///;q;}' ${EXPERIMENT_DIR}/train.log > ${EXPERIMENT_DIR}/shortened_train.log\n",
    "  grep -e \"Train perplexity\" -e \"Validation perplexity\" ${EXPERIMENT_DIR}/train.log >> ${EXPERIMENT_DIR}/shortened_train.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPx7cchpgtA_"
   },
   "source": [
    "Perfrom translation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zu9JtZlPgvOt"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate BachelorThesisST\n",
    "# ----------- Activate the conda env in every cell, neccessary if using Google colab. Remove the above lines if not needed -----------\n",
    "DATA_DIR=data/CoVoST2/preprocessed/one_seventy/nl-en\n",
    "SUB_DIR=mix_nl_text_de\n",
    "MODEL_DIR=models/${SUB_DIR}_dummy\n",
    "EXPERIMENT_DIR=experiments/${SUB_DIR}_dummy\n",
    "CHOSEN_MODEL_NAME=$(python finding_best_model.py -model_dir ${MODEL_DIR})\n",
    "echo \"Evaluating ST\"\n",
    "python translate.py -model ${MODEL_DIR}/$CHOSEN_MODEL_NAME \\\n",
    "    -src $DATA_DIR/nl_audio_test.scp \\\n",
    "    -src_lang nl \\\n",
    "    -tgt_lang en \\\n",
    "    -concat 4 \\\n",
    "    -asr_format scp \\\n",
    "    -encoder_type audio \\\n",
    "    -tgt $DATA_DIR/en_text_test.txt  \\\n",
    "    -output ${EXPERIMENT_DIR}/encoded_translations_st.txt \\\n",
    "    -batch_size 5 \\\n",
    "    -max_sent_length 1024 \\\n",
    "    -gpu 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ITPE_QajNyO"
   },
   "source": [
    "Evaluate the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFcDwmZEjPyF"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate BachelorThesisST\n",
    "# ----------- Activate the conda env in every cell, neccessary if using Google colab. Remove the above lines if not needed -----------\n",
    "DATA_DIR=data/CoVoST2/preprocessed/one_seventy/nl-en\n",
    "SUB_DIR=mix_nl_text_de\n",
    "EXPERIMENT_DIR=experiments/${SUB_DIR}_dummy\n",
    "python translation_evaluation.py -save_data ${EXPERIMENT_DIR} \\\n",
    "      -encoded_output_text ${EXPERIMENT_DIR}/encoded_translations_st.txt \\\n",
    "      -text_encoder_decoder $DATA_DIR/en_text.model \\\n",
    "      -reference_text $DATA_DIR/en_raw_text_test.txt \\\n",
    "      -task translation \\\n",
    "      -specific_task st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNab2ZyjjuBt"
   },
   "source": [
    "The following shell scripts run the preprocess-train-eval pipeline:\n",
    "- `run_translation_pipeline.sh` for single-task models\n",
    "- `cascaded_ST_evaluation.sh` evaluates cascaded ST using pretrained ASR and MT models\n",
    "- `run_translation_multi_modalities_pipeline.sh` for multi-task, multi-modality models (including zero-shot)\n",
    "- `run_zeroshot_with_artificial_data.sh` for zero-shot models using data augmentation\n",
    "- `run_bidirectional_zeroshot.sh` for zero-shot models using additional opposite training data\n",
    "- `run_fine_tunning.sh`, `run_fine_tunning_fromASR.sh` for fine-tuning pre-trained models\n",
    "- `modality_similarity_svcca.sh`, `modality_similarity_classifier.sh` measure text-audio similarity in representation\n",
    "\n",
    "See the shell script comments to modify the variables as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a_2Xc8360k3"
   },
   "outputs": [],
   "source": [
    "while True: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J49cMho2ngRJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Repo_Instruction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
