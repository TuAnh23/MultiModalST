{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Change the working directory to the root of the project\n",
    "os.chdir(r'C:\\Users\\TuAhnDinh\\Desktop\\MediaanProjects\\BachelorThesisST')\n",
    "\n",
    "COVOST_DIR = 'data/CoVoST2'\n",
    "\n",
    "# Downloads voice clips and transcripts\n",
    "urls = {'en': 'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/en.tar.gz',\n",
    "        'fr': 'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/fr.tar.gz',\n",
    "        'de': 'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/de.tar.gz',\n",
    "        'it': 'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/it.tar.gz',\n",
    "        'pt': 'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/pt.tar.gz',\n",
    "        'es': 'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/es.tar.gz',\n",
    "        'nl': 'https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/nl.tar.gz'}\n",
    "\n",
    "for lang, url in urls.items():\n",
    "    lang_dir = COVOST_DIR + '/' + lang\n",
    "    if not os.path.exists(lang_dir):\n",
    "        print(f'Downloading {lang} audios')\n",
    "        filename = url.rsplit('/', 1)[1]\n",
    "        r = requests.get(url)\n",
    "        with open(COVOST_DIR + '/' + filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(f'Extracting {lang} audios')\n",
    "        tf = tarfile.open(COVOST_DIR + '/' + filename)\n",
    "        tf.extractall(lang_dir)\n",
    "        tf.close()\n",
    "        os.remove(COVOST_DIR + '/' + filename)\n",
    "\n",
    "XX_EN_LANGUAGES  = ['fr', 'de', 'it', 'pt', 'es', 'nl']\n",
    "EN_XX_LANGUAGES  = ['de', 'et']\n",
    "# Download CoVoST 2 translations (covost_v2.<src_lang_code>_<tgt_lang_code>.tsv, \n",
    "# which matches the rows in validated.tsv from Common Voice)\n",
    "if not os.path.exists(COVOST_DIR + '/covost2'):\n",
    "    os.mkdir(COVOST_DIR + '/covost2')\n",
    "for lang in XX_EN_LANGUAGES:\n",
    "    if not os.path.exists(COVOST_DIR + '/covost2' + f'/{lang}_en'):\n",
    "        os.mkdir(COVOST_DIR + '/covost2'+ f'/{lang}_en')\n",
    "        # Download and extract .tsv file\n",
    "        url = f'https://dl.fbaipublicfiles.com/covost/covost_v2.{lang}_en.tsv.tar.gz'\n",
    "        filename = url.rsplit('/', 1)[1]\n",
    "        print(f'Download and extracting {filename}')\n",
    "        r = requests.get(url)\n",
    "        with open(COVOST_DIR + '/covost2' + f'/{lang}_en' + f'/{filename}', 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        tf = tarfile.open(COVOST_DIR + '/covost2' + f'/{lang}_en' + f'/{filename}')\n",
    "        tf.extractall(COVOST_DIR + '/covost2' + f'/{lang}_en')\n",
    "        tf.close()\n",
    "        os.remove(COVOST_DIR + '/covost2' + f'/{lang}_en' + f'/{filename}')\n",
    "        \n",
    "        # Split .tsv file into train, dev and test set\n",
    "        os.system(f\"python get_covost_splits.py \"\n",
    "                  f\"--version 2 --src-lang {lang} --tgt-lang en \"\n",
    "                  f\"--root {COVOST_DIR + '/covost2' + f'/{lang}_en'} \"\n",
    "                  f\"--cv-tsv {COVOST_DIR + '/' + lang + '/validated.tsv'}\")\n",
    "        \n",
    "for lang in EN_XX_LANGUAGES:\n",
    "    if not os.path.exists(COVOST_DIR + '/covost2' + f'/en_{lang}'):\n",
    "        os.mkdir(COVOST_DIR + '/covost2'+ f'/en_{lang}')\n",
    "        # Download and extract .tsv file\n",
    "        url = f'https://dl.fbaipublicfiles.com/covost/covost_v2.en_{lang}.tsv.tar.gz'\n",
    "        filename = url.rsplit('/', 1)[1]\n",
    "        print(f'Download and extracting {filename}')\n",
    "        r = requests.get(url)\n",
    "        with open(COVOST_DIR + '/covost2' + f'/en_{lang}' + f'/{filename}', 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        tf = tarfile.open(COVOST_DIR + '/covost2' + f'/en_{lang}' + f'/{filename}')\n",
    "        tf.extractall(COVOST_DIR + '/covost2' + f'/en_{lang}')\n",
    "        tf.close()\n",
    "        os.remove(COVOST_DIR + '/covost2' + f'/en_{lang}' + f'/{filename}')\n",
    "        \n",
    "        # Split .tsv file into train, dev and test set\n",
    "        os.system(f\"python get_covost_splits.py \"\n",
    "                  f\"--version 2 --src-lang en --tgt-lang {lang} \"\n",
    "                  f\"--root {COVOST_DIR + '/covost2' + f'/en_{lang}'} \"\n",
    "                  f\"--cv-tsv {COVOST_DIR + '/' + 'en' + '/validated.tsv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on data split**: \n",
    "\n",
    "- Use standard Common Voice dev/test splits (no duplicated sentences)\n",
    "- Use extended Common Voice train split to improve data utilization (include all duplicated sentences with different speakers)\n",
    "\n",
    "More info on the [Covost2 paper](https://arxiv.org/pdf/2007.10310.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function to remove empty .mp3 audio lines from a split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_audio(split_df, audiodir):\n",
    "    empty = []\n",
    "    paths = split_df['path'].values\n",
    "    for path in paths:\n",
    "        if os.path.getsize(audiodir + '/' + path) == 0:\n",
    "            print(f\"found {path} to be empty\")\n",
    "            empty.append(path)\n",
    "    new_df = split_df.set_index('path')\n",
    "    new_df.drop(labels=empty, axis='index', inplace=True)\n",
    "    new_df.reset_index(inplace=True)\n",
    "    return new_df\n",
    "\n",
    "def remove_empty_transcription(split_df):\n",
    "    new_df = split_df.loc[(split_df['sentence'] != \"\") & (split_df['sentence'] != '\"\"') & (split_df['translation'] != \"\") & (split_df['translation'] != '\"\"')]\n",
    "    return new_df\n",
    "    \n",
    "def read_tsv_split(translation_dir, src_lang, tgt_lang, split, audiodir):\n",
    "    split_df = pd.read_csv(translation_dir + f'/covost_v2.{src_lang}_{tgt_lang}.{split}.tsv', sep='\\t', header=0, encoding=\"utf-8\", escapechar=\"\\\\\", quoting=csv.QUOTE_NONE, na_filter=False)\n",
    "    return remove_empty_transcription(remove_empty_audio(split_df, audiodir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at Dutch --> English as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUTCH_AUDIO_DIR = COVOST_DIR + '/nl'\n",
    "NL_EN_TRANSLATIONS_DIR = COVOST_DIR + '/covost2' + '/nl_en'\n",
    "nl_en_translations_dev = pd.read_csv(NL_EN_TRANSLATIONS_DIR + '/covost_v2.nl_en.dev.tsv', sep='\\t', header=0, encoding=\"utf-8\", escapechar=\"\\\\\", quoting=csv.QUOTE_NONE, na_filter=False)\n",
    "nl_en_translations_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some samples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "n_samples = 3\n",
    "for i in range (0, n_samples):\n",
    "    print('- Audio:')\n",
    "    audio_path = DUTCH_AUDIO_DIR + '/clips/' + nl_en_translations_dev.loc[i]['path']\n",
    "    print(audio_path)\n",
    "    display(Audio(filename=audio_path, autoplay=False))\n",
    "    print('- Transcription - nl:')\n",
    "    print(nl_en_translations_dev.loc[i]['sentence'])\n",
    "    print('- Translated transcription - en:')\n",
    "    print(nl_en_translations_dev.loc[i]['translation'])\n",
    "    print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "\n",
    "# X_en_stat = pd.DataFrame(columns=[['numb. of audios','numb. of audios','numb. of audios',\n",
    "#                                    'numb. of unique sentence auios','numb. of unique sentence auios','numb. of unique sentence auios',\n",
    "#                                    'avg audio length (s)','avg audio length (s)','avg audio length (s)',\n",
    "#                                    'avg numb. of words per audio','avg numb. of words per audio','avg numb. of words per audio'],\n",
    "#                                  ['train','dev','test',\n",
    "#                                   'train','dev','test',\n",
    "#                                   'train','dev','test',\n",
    "#                                   'train', 'dev','test']])\n",
    "\n",
    "# for lang in XX_EN_LANGUAGES:\n",
    "#     SRC_AUDIO_DIR = COVOST_DIR + '/' + lang\n",
    "#     audiodir = SRC_AUDIO_DIR + '/clips'\n",
    "#     TRANSLATIONS_DIR =  COVOST_DIR + '/covost2' + f'/{lang}_en'\n",
    "#     for split in ['train', 'dev', 'test']:\n",
    "#         split_df = read_tsv_split(TRANSLATIONS_DIR, src_lang=lang, tgt_lang='en', split=split, audiodir=audiodir)\n",
    "#         X_en_stat.at[lang, ('numb. of audios', split)] = len(split_df)\n",
    "#         X_en_stat.at[lang, ('numb. of unique sentence auios', split)] = len(set(split_df['sentence'].values))\n",
    "#         X_en_stat.at[lang, ('avg audio length (s)', split)] = np.mean(np.array([librosa.get_duration(filename=audiodir + '/' + path) for path in split_df['path'].values]))\n",
    "#         X_en_stat.at[lang, ('avg numb. of words per audio', split)] = np.mean(np.array([len(s.split()) for s in split_df['sentence'].values]))\n",
    "\n",
    "# X_en_stat.to_csv(COVOST_DIR + '/' + 'X_en_stat.csv')\n",
    "\n",
    "X_en_stat = pd.read_csv(COVOST_DIR + '/' + 'X_en_stat.csv', index_col=0, header=[0,1])\n",
    "X_en_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_X_stat = pd.DataFrame(columns=[['numb. of audios','numb. of audios','numb. of audios',\n",
    "#                                    'numb. of unique sentence auios','numb. of unique sentence auios','numb. of unique sentence auios',\n",
    "#                                    'avg audio length (s)','avg audio length (s)','avg audio length (s)',\n",
    "#                                    'avg numb. of words per audio','avg numb. of words per audio','avg numb. of words per audio'],\n",
    "#                                  ['train','dev','test',\n",
    "#                                   'train','dev','test',\n",
    "#                                   'train','dev','test',\n",
    "#                                   'train', 'dev','test']])\n",
    "\n",
    "# for lang in EN_XX_LANGUAGES:\n",
    "#     SRC_AUDIO_DIR = COVOST_DIR + '/' + 'en'\n",
    "#     audiodir = SRC_AUDIO_DIR + '/clips'\n",
    "#     TRANSLATIONS_DIR =  COVOST_DIR + '/covost2' + f'/en_{lang}'\n",
    "#     for split in ['train', 'dev', 'test']:\n",
    "#         split_df = read_tsv_split(TRANSLATIONS_DIR, src_lang='en', tgt_lang=lang, split=split, audiodir=audiodir)\n",
    "#         en_X_stat.at[lang, ('numb. of audios', split)] = len(split_df)\n",
    "#         en_X_stat.at[lang, ('numb. of unique sentence auios', split)] = len(set(split_df['sentence'].values))\n",
    "#         en_X_stat.at[lang, ('avg audio length (s)', split)] = np.mean(np.array([librosa.get_duration(filename=audiodir + '/' + path) for path in split_df['path'].values]))\n",
    "#         en_X_stat.at[lang, ('avg numb. of words per audio', split)] = np.mean(np.array([len(s.split()) for s in split_df['sentence'].values]))\n",
    "\n",
    "# en_X_stat.to_csv(COVOST_DIR + '/' + 'en_X_stat.csv')        \n",
    "\n",
    "en_X_stat = pd.read_csv(COVOST_DIR + '/' + 'en_X_stat.csv', index_col=0, header=[0,1])\n",
    "en_X_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess a sample dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location to save the preprocessed data\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'de'\n",
    "preprocessed_dir = f'preprocessed/{src_lang}_{tgt_lang}'\n",
    "os.mkdir(f'{COVOST_DIR}/{preprocessed_dir}')\n",
    "\n",
    "SRC_AUDIO_DIR = COVOST_DIR + '/' + src_lang\n",
    "audiodir = SRC_AUDIO_DIR + '/clips'\n",
    "\n",
    "TRANSLATIONS_DIR =  COVOST_DIR + '/covost2' + f'/{src_lang}_{tgt_lang}'\n",
    "train_df = read_tsv_split(TRANSLATIONS_DIR, src_lang=src_lang, tgt_lang=tgt_lang, split='train', audiodir=audiodir)\n",
    "val_df = read_tsv_split(TRANSLATIONS_DIR, src_lang=src_lang, tgt_lang=tgt_lang, split='dev', audiodir=audiodir)\n",
    "test_df = read_tsv_split(TRANSLATIONS_DIR, src_lang=src_lang, tgt_lang=tgt_lang, split='test', audiodir=audiodir)\n",
    "\n",
    "train_audios_list = [audiodir + '/' + path for path in train_df['path']]\n",
    "val_audios_list = [audiodir + '/' + path for path in val_df['path']]\n",
    "test_audios_list = [audiodir + '/' + path for path in test_df['path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the audios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since librosa does not deal with `.mp3` files, we need a wrapper function to load `.mp3` audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Create a .wav verson of a .mp3 file in the same location, and return the path to the .wav file\n",
    "def mp3_to_wav(mp3_path):\n",
    "    wav_path = f\"{mp3_path[:-4]}.wav\"\n",
    "    gf = os.system(f\"\"\"ffmpeg -i {mp3_path} {wav_path}\"\"\")\n",
    "    return wav_path\n",
    "    \n",
    "# Wrapper function to load .mp3 audio\n",
    "def load_mp3(mp3_path, sr=22050, mono=True, offset=0.0, duration=None, dtype=np.float32, res_type='kaiser_best'):\n",
    "    wav_path = mp3_to_wav(mp3_path)\n",
    "    signal, sample_rate = librosa.load(wav_path, sr, mono, offset, duration, dtype, res_type)\n",
    "    # Remove the .wav file when we're done\n",
    "    os.remove(wav_path)\n",
    "    return signal, sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the MFCC features of the audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import logfbank, calculate_delta, normalize\n",
    "from kaldiio import WriteHelper\n",
    "\n",
    "def preprocess_audios(audio_paths, output_file_prefix):\n",
    "    out_ark = output_file_prefix + \".ark\"\n",
    "    out_scp = output_file_prefix + \".scp\"\n",
    "    count=0\n",
    "\n",
    "    with WriteHelper('ark,scp:'+out_ark+','+out_scp) as writer:\n",
    "        for audio in audio_paths:\n",
    "            if audio.endswith('.mp3'):\n",
    "                signal, sample_rate = load_mp3(audio, sr=16000)\n",
    "            else:\n",
    "                signal, sample_rate = librosa.load(audio, sr=16000)\n",
    "            logmel = logfbank(signal, samplerate=sample_rate)\n",
    "            delta = calculate_delta(logmel)\n",
    "            features = np.concatenate([logmel, delta], axis=1)\n",
    "            features = normalize(features) # features.shape gives (x, 80)\n",
    "            writer(str(count), features)\n",
    "            count = count + 1\n",
    "    return out_ark, out_scp\n",
    "            \n",
    "preprocess_audios(train_audios_list, f'{COVOST_DIR}/{preprocessed_dir}/{src_lang}_audio_train')\n",
    "preprocess_audios(val_audios_list, f'{COVOST_DIR}/{preprocessed_dir}/{src_lang}_audio_val')\n",
    "preprocess_audios(test_audios_list, f'{COVOST_DIR}/{preprocessed_dir}/{src_lang}_audio_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a text file with one-sentence-per-line from the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_transcription(info_df, audio_paths, output_file_prefix, transcription_type='translated'):\n",
    "    \"\"\" transcription_type is either 'original' or 'translated'\n",
    "    \"\"\"\n",
    "    info_df_re_indexed = info_df.set_index('path')\n",
    "    with open(f\"{output_file_prefix}.txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "        for audio_path in audio_paths:\n",
    "            # write line to output file\n",
    "            audio_name = os.path.basename(audio_path)\n",
    "            if transcription_type == 'original':\n",
    "                out_file.write(prepare_sentence(info_df_re_indexed.loc[audio_name]['sentence']))\n",
    "            elif transcription_type == 'translated':\n",
    "                out_file.write(prepare_sentence(info_df_re_indexed.loc[audio_name]['translation']))\n",
    "            else:\n",
    "                raise RuntimeError(\"transcription_type is either 'original' or 'translated'\")\n",
    "            out_file.write(\"\\n\")\n",
    "    return f\"{output_file_prefix}.txt\"\n",
    "\n",
    "def prepare_sentence(sentence):\n",
    "    if sentence.startswith('\"') and sentence.endswith('\"'):\n",
    "        return sentence[1:-1]\n",
    "    return sentence\n",
    "             \n",
    "raw_text_train_path = collect_transcription(train_df, train_audios_list, f'{COVOST_DIR}/{preprocessed_dir}/{tgt_lang}_raw_text_train')\n",
    "raw_text_val_path = collect_transcription(val_df, val_audios_list, f'{COVOST_DIR}/{preprocessed_dir}/{tgt_lang}_raw_text_val')\n",
    "raw_text_test_path = collect_transcription(test_df, test_audios_list, f'{COVOST_DIR}/{preprocessed_dir}/{tgt_lang}_raw_text_test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [subword units](https://github.com/google/sentencepiece) to preprocess the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword_unit(model_path, raw_text_file, output_file, output_type=int):\n",
    "    \"\"\"\n",
    "    Use a Sentence Piece model to do subword unit on a text file\n",
    "    \"\"\"\n",
    "    sp = spm.SentencePieceProcessor(model_file=model_path)\n",
    "    with open(raw_text_file, 'r', encoding=\"utf-8\") as f:\n",
    "        raw_lines = f.readlines()\n",
    "    processed_lines = [' '.join([str(elem) for elem in sp.encode(line, out_type=output_type)]) for line in raw_lines]\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for line in processed_lines:\n",
    "            f.write(line)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transcription(transcription_type, train_df, val_df, test_df, train_audios_list, val_audios_list, test_audios_list,\n",
    "                    save_location, lang):\n",
    "    raw_text_train_path = collect_transcription(train_df, train_audios_list, f'{save_location}/{lang}_raw_text_train', transcription_type)\n",
    "    raw_text_val_path = collect_transcription(val_df, val_audios_list, f'{save_location}/{lang}_raw_text_val', transcription_type)\n",
    "    raw_text_test_path = collect_transcription(test_df, test_audios_list, f'{save_location}/{lang}_raw_text_test', transcription_type)\n",
    "\n",
    "    # Train the model to do subword unit on the text\n",
    "    input_file = raw_text_train_path  # one-sentence-per-line raw corpus file\n",
    "    model_prefix = f'{save_location}/{lang}_text'\n",
    "    vocab_size = 8000  # 8000, 16000, or 32000\n",
    "    if lang == 'zh-CN' or lang == 'ja':\n",
    "        character_coverage = 0.9995  # 0.9995 for languages with rich character set like Japanese or Chinese\n",
    "    else:\n",
    "        character_coverage = 1  # and 1.0 for other languages with small character set\n",
    "    model_type = 'unigram'\n",
    "    spm.SentencePieceTrainer.train(input=input_file, model_prefix=model_prefix, vocab_size=vocab_size,\n",
    "                                   character_coverage=character_coverage, model_type=model_type)\n",
    "    \n",
    "    subword_unit(f\"{model_prefix}.model\", raw_text_train_path,\n",
    "                    f'{save_location}/{lang}_text_train.txt')\n",
    "    subword_unit(f\"{model_prefix}.model\", raw_text_val_path,\n",
    "                    f'{save_location}/{lang}_text_val.txt')\n",
    "    subword_unit(f\"{model_prefix}.model\", raw_text_test_path,\n",
    "                    f'{save_location}/{lang}_text_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "preprocess_transcription('original', train_df, val_df, test_df, train_audios_list, val_audios_list, test_audios_list, \n",
    "                         f'{COVOST_DIR}/{preprocessed_dir}', src_lang)\n",
    "preprocess_transcription('translated', train_df, val_df, test_df, train_audios_list, val_audios_list, test_audios_list, \n",
    "                         f'{COVOST_DIR}/{preprocessed_dir}', tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
